{"nbformat": 4, "nbformat_minor": 0, "metadata": {"colab": {"provenance": [], "authorship_tag": "ABX9TyNMu8k3MfJUR3czm6IhX1oR", "include_colab_link": true}, "kernelspec": {"name": "python3", "display_name": "Python 3"}, "language_info": {"name": "python"}}, "cells": [{"cell_type": "code", "metadata": {}, "source": ["import numpy as np\n", "import pandas as pd\n", "import seaborn as sns\n", "import matplotlib.pyplot as plt\n", "from sklearn.model_selection import train_test_split, cross_val_score\n", "from sklearn.linear_model import LinearRegression, Ridge\n", "from sklearn.ensemble import RandomForestRegressor\n", "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n", "import joblib\n", "\n", "# Load dataset (relative path for portability)\n", "df = pd.read_csv('student.csv')\n", "df.head()"]}, {"cell_type": "code", "metadata": {}, "source": ["print('Total number of students:', len(df))\n", "print('\\nColumns:', df.columns.tolist())\n", "print('\\nDataset Info:')\n", "df.info()\n", "print('\\nSummary Statistics:')\n", "display(df.describe())"]}, {"cell_type": "code", "metadata": {}, "source": ["# Correlation Heatmap\n", "plt.figure(figsize=(10,6))\n", "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt='.2f')\n", "plt.title('Correlation Heatmap')\n", "plt.show()"]}, {"cell_type": "code", "metadata": {}, "source": ["# Define features (X) and target (y)\n", "X = df.drop('G3', axis=1)  # Assuming 'G3' is the target (final grade)\n", "y = df['G3']\n", "\n", "# Train-test split\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"]}, {"cell_type": "code", "metadata": {}, "source": ["# Initialize models\n", "models = {\n", "    'Linear Regression': LinearRegression(),\n", "    'Ridge Regression': Ridge(alpha=1.0),\n", "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42)\n", "}\n", "\n", "results = {}\n", "for name, model in models.items():\n", "    model.fit(X_train, y_train)\n", "    y_pred = model.predict(X_test)\n", "    mae = mean_absolute_error(y_test, y_pred)\n", "    mse = mean_squared_error(y_test, y_pred)\n", "    rmse = np.sqrt(mse)\n", "    r2 = r2_score(y_test, y_pred)\n", "    results[name] = {'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'R2': r2}\n", "\n", "# Display results\n", "results_df = pd.DataFrame(results).T\n", "results_df"]}, {"cell_type": "code", "metadata": {}, "source": ["# Compare Actual vs Predicted for the best model\n", "best_model_name = results_df['R2'].idxmax()\n", "best_model = models[best_model_name]\n", "y_pred_best = best_model.predict(X_test)\n", "\n", "plt.figure(figsize=(8,6))\n", "sns.scatterplot(x=y_test, y=y_pred_best, alpha=0.7)\n", "plt.xlabel('Actual Grades')\n", "plt.ylabel('Predicted Grades')\n", "plt.title(f'Actual vs Predicted ({best_model_name})')\n", "plt.show()"]}, {"cell_type": "code", "metadata": {}, "source": ["# Save the best performing model\n", "joblib.dump(best_model, f'{best_model_name.replace(\" \", \"_\").lower()}_model.pkl')\n", "print(f'Best model \"{best_model_name}\" saved successfully!')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### \ud83d\udccc Conclusion\n", "- Multiple models were tested (Linear Regression, Ridge Regression, Random Forest).\n", "- The results table shows performance metrics (MAE, MSE, RMSE, R\u00b2).\n", "- The best performing model is automatically identified and saved.\n", "- Random Forest usually performs best due to its ability to capture nonlinear patterns, but results depend on dataset characteristics.\n", "\n", "\u2705 This notebook is now portable, more robust, and professional."]}]}